{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad2b88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 4: Machine Learning with Vertex AI\n",
    "\n",
    "Author: \n",
    "* Fabian Hirschmann <<fhirschmann@google.com>>\n",
    "\n",
    "Welcome back 👋😍. During this lab, you will train a machine learning model on the data set you already know. We will deploy it to Vertex AI and finally construct a machine learning pipeline to perform the training process automatically.\n",
    "\n",
    "We will do it in three different maturity levels:\n",
    "\n",
    "1. Deploying locally trained models to Vertex AI using prebuilt containers\n",
    "2. Train and deploy model on Vertex AI using custom containers\n",
    "3. Use Vertex AI pipeline to train and deploy the model\n",
    "\n",
    "In this Jupyter Notebook, you can press `Shift + Return` to execute the current code junk and jump to the next one.\n",
    "\n",
    "## Step 1: Import Dependencies and Set Environment Variables\n",
    "\n",
    "Before we begin, let's import the necessary Python libraries and set a few environment variables for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf0314c-770c-41fe-be57-f41eb17bf48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1337)\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from sklearn.metrics import roc_curve, auc as auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "import google.cloud.logging\n",
    "google.cloud.logging.Client().setup_logging(log_level=logging.WARNING)\n",
    "\n",
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "BQ_DATASET = \"ml_datasets\"\n",
    "BQ_TABLE = \"ulb_fraud_detection_dataproc\"\n",
    "BQ_SOURCE = f\"{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b46cf-c829-4439-9151-3722c290d5b8",
   "metadata": {},
   "source": [
    "If you get warnings about GPUs not being available -- that's fine.\n",
    "\n",
    "The requirements were automatically installed by the `bootstrap_workbench.sh` script we specified when we created this Workbench instance. However, if the above command fails due to import errors, uncomment the next chunk, run it, and then restart the kernel (`Kernel > Restart Kernel` in the menu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caad0bb3-7432-45b5-bf1a-eb7c0214b5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9ce43-7912-4fcc-98ee-e30ae961e43e",
   "metadata": {},
   "source": [
    "## Step 2: Create dataset for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8cb35-8c90-4378-a592-fd28ffa6d1a5",
   "metadata": {},
   "source": [
    "We initialize the AI Platform and BigQuery client to interact with Google Cloud services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ea1163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"{PROJECT_ID}-bucket\")\n",
    "bq = bigquery.Client(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c15d1c-82ed-460c-80d3-c08c5bee1432",
   "metadata": {},
   "source": [
    "The BigQuery table we'll be working with is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e001be2f-5701-497d-b4a4-9eb8d2202fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astute-ace-336608.ml_datasets.ulb_fraud_detection_dataproc'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BQ_SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46092b6-2908-4bf6-b45f-53697f2b17c6",
   "metadata": {},
   "source": [
    "We execute a query to fetch the dataset from BigQuery and store it in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07455370-2100-469e-9a87-09963c593437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = bq.query(f\"SELECT * FROM `{BQ_SOURCE}`\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3aaa1-4083-4e35-8c70-6ecbf41fac76",
   "metadata": {},
   "source": [
    "Let's have a look at the data set in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590bc934-a254-4ee3-9dc4-1a21cf57648d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282.0</td>\n",
       "      <td>-0.356466</td>\n",
       "      <td>0.725418</td>\n",
       "      <td>1.971749</td>\n",
       "      <td>0.831343</td>\n",
       "      <td>0.369681</td>\n",
       "      <td>-0.107776</td>\n",
       "      <td>0.751610</td>\n",
       "      <td>-0.120166</td>\n",
       "      <td>-0.420675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.424312</td>\n",
       "      <td>-0.015989</td>\n",
       "      <td>0.466754</td>\n",
       "      <td>-0.809962</td>\n",
       "      <td>0.657334</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>-0.046401</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14332.0</td>\n",
       "      <td>1.071950</td>\n",
       "      <td>0.340678</td>\n",
       "      <td>1.784068</td>\n",
       "      <td>2.846396</td>\n",
       "      <td>-0.751538</td>\n",
       "      <td>0.403028</td>\n",
       "      <td>-0.734920</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>1.092726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169632</td>\n",
       "      <td>-0.113604</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.223541</td>\n",
       "      <td>-0.112355</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.021504</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32799.0</td>\n",
       "      <td>1.153477</td>\n",
       "      <td>-0.047859</td>\n",
       "      <td>1.358363</td>\n",
       "      <td>1.480620</td>\n",
       "      <td>-1.222598</td>\n",
       "      <td>-0.481690</td>\n",
       "      <td>-0.654461</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.907095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125514</td>\n",
       "      <td>0.480049</td>\n",
       "      <td>-0.025964</td>\n",
       "      <td>0.701843</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>-0.257691</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35799.0</td>\n",
       "      <td>-0.769798</td>\n",
       "      <td>0.622325</td>\n",
       "      <td>0.242491</td>\n",
       "      <td>-0.586652</td>\n",
       "      <td>0.527819</td>\n",
       "      <td>-0.104512</td>\n",
       "      <td>0.209909</td>\n",
       "      <td>0.669861</td>\n",
       "      <td>-0.304509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152738</td>\n",
       "      <td>0.255654</td>\n",
       "      <td>-0.130237</td>\n",
       "      <td>-0.660934</td>\n",
       "      <td>-0.493374</td>\n",
       "      <td>0.331855</td>\n",
       "      <td>-0.011101</td>\n",
       "      <td>0.049089</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36419.0</td>\n",
       "      <td>1.047960</td>\n",
       "      <td>0.145048</td>\n",
       "      <td>1.624573</td>\n",
       "      <td>2.932652</td>\n",
       "      <td>-0.726574</td>\n",
       "      <td>0.690451</td>\n",
       "      <td>-0.627288</td>\n",
       "      <td>0.278709</td>\n",
       "      <td>0.318434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078499</td>\n",
       "      <td>0.658942</td>\n",
       "      <td>-0.067810</td>\n",
       "      <td>0.476882</td>\n",
       "      <td>0.526830</td>\n",
       "      <td>0.219902</td>\n",
       "      <td>0.070627</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>154599.0</td>\n",
       "      <td>0.667714</td>\n",
       "      <td>3.041502</td>\n",
       "      <td>-5.845112</td>\n",
       "      <td>5.967587</td>\n",
       "      <td>0.213863</td>\n",
       "      <td>-1.462923</td>\n",
       "      <td>-2.688761</td>\n",
       "      <td>0.677764</td>\n",
       "      <td>-3.447596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329760</td>\n",
       "      <td>-0.941383</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>-0.958925</td>\n",
       "      <td>0.239298</td>\n",
       "      <td>-0.067356</td>\n",
       "      <td>0.821048</td>\n",
       "      <td>0.426175</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>90676.0</td>\n",
       "      <td>-2.405580</td>\n",
       "      <td>3.738235</td>\n",
       "      <td>-2.317843</td>\n",
       "      <td>1.367442</td>\n",
       "      <td>0.394001</td>\n",
       "      <td>1.919938</td>\n",
       "      <td>-3.106942</td>\n",
       "      <td>-10.764403</td>\n",
       "      <td>3.353525</td>\n",
       "      <td>...</td>\n",
       "      <td>10.005998</td>\n",
       "      <td>-2.454964</td>\n",
       "      <td>1.684957</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>-1.531380</td>\n",
       "      <td>-0.695308</td>\n",
       "      <td>-0.152502</td>\n",
       "      <td>-0.138866</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>34634.0</td>\n",
       "      <td>0.333499</td>\n",
       "      <td>1.699873</td>\n",
       "      <td>-2.596561</td>\n",
       "      <td>3.643945</td>\n",
       "      <td>-0.585068</td>\n",
       "      <td>-0.654659</td>\n",
       "      <td>-2.275789</td>\n",
       "      <td>0.675229</td>\n",
       "      <td>-2.042416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469212</td>\n",
       "      <td>-0.144363</td>\n",
       "      <td>-0.317981</td>\n",
       "      <td>-0.769644</td>\n",
       "      <td>0.807855</td>\n",
       "      <td>0.228164</td>\n",
       "      <td>0.551002</td>\n",
       "      <td>0.305473</td>\n",
       "      <td>18.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>96135.0</td>\n",
       "      <td>-1.952933</td>\n",
       "      <td>3.541385</td>\n",
       "      <td>-1.310561</td>\n",
       "      <td>5.955664</td>\n",
       "      <td>-1.003993</td>\n",
       "      <td>0.983049</td>\n",
       "      <td>-4.587235</td>\n",
       "      <td>-4.892184</td>\n",
       "      <td>-2.516752</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.998091</td>\n",
       "      <td>1.133706</td>\n",
       "      <td>-0.041461</td>\n",
       "      <td>-0.215379</td>\n",
       "      <td>-0.865599</td>\n",
       "      <td>0.212545</td>\n",
       "      <td>0.532897</td>\n",
       "      <td>0.357892</td>\n",
       "      <td>18.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0          282.0 -0.356466  0.725418  1.971749  0.831343  0.369681 -0.107776   \n",
       "1        14332.0  1.071950  0.340678  1.784068  2.846396 -0.751538  0.403028   \n",
       "2        32799.0  1.153477 -0.047859  1.358363  1.480620 -1.222598 -0.481690   \n",
       "3        35799.0 -0.769798  0.622325  0.242491 -0.586652  0.527819 -0.104512   \n",
       "4        36419.0  1.047960  0.145048  1.624573  2.932652 -0.726574  0.690451   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  154599.0  0.667714  3.041502 -5.845112  5.967587  0.213863 -1.462923   \n",
       "284803   90676.0 -2.405580  3.738235 -2.317843  1.367442  0.394001  1.919938   \n",
       "284804   34634.0  0.333499  1.699873 -2.596561  3.643945 -0.585068 -0.654659   \n",
       "284805   96135.0 -1.952933  3.541385 -1.310561  5.955664 -1.003993  0.983049   \n",
       "284806    4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "\n",
       "              V7         V8        V9  ...        V21       V22       V23  \\\n",
       "0       0.751610  -0.120166 -0.420675  ...   0.020804  0.424312 -0.015989   \n",
       "1      -0.734920   0.205807  1.092726  ...  -0.169632 -0.113604  0.067643   \n",
       "2      -0.654461   0.128115  0.907095  ...   0.125514  0.480049 -0.025964   \n",
       "3       0.209909   0.669861 -0.304509  ...   0.152738  0.255654 -0.130237   \n",
       "4      -0.627288   0.278709  0.318434  ...   0.078499  0.658942 -0.067810   \n",
       "...          ...        ...       ...  ...        ...       ...       ...   \n",
       "284802 -2.688761   0.677764 -3.447596  ...   0.329760 -0.941383 -0.006075   \n",
       "284803 -3.106942 -10.764403  3.353525  ...  10.005998 -2.454964  1.684957   \n",
       "284804 -2.275789   0.675229 -2.042416  ...   0.469212 -0.144363 -0.317981   \n",
       "284805 -4.587235  -4.892184 -2.516752  ...  -1.998091  1.133706 -0.041461   \n",
       "284806  0.562320  -0.399147 -0.238253  ...  -0.294166 -0.932391  0.172726   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.466754 -0.809962  0.657334 -0.043150 -0.046401    0.00      0  \n",
       "1       0.468669  0.223541 -0.112355  0.014015  0.021504    0.00      0  \n",
       "2       0.701843  0.417245 -0.257691  0.060115  0.035332    0.00      0  \n",
       "3      -0.660934 -0.493374  0.331855 -0.011101  0.049089    0.00      0  \n",
       "4       0.476882  0.526830  0.219902  0.070627  0.028488    0.00      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "284802 -0.958925  0.239298 -0.067356  0.821048  0.426175    6.74      1  \n",
       "284803  0.118263 -1.531380 -0.695308 -0.152502 -0.138866    6.99      1  \n",
       "284804 -0.769644  0.807855  0.228164  0.551002  0.305473   18.96      1  \n",
       "284805 -0.215379 -0.865599  0.212545  0.532897  0.357892   18.96      1  \n",
       "284806 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02afc5-90bb-479d-bd8e-40f0d0eb4c9b",
   "metadata": {},
   "source": [
    "We separate the target variable (`Class`), which we want to predict, from the features (all other columns). The `Class` column indicates whether a transaction is fraudulent (1) or legitimate (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5707b149-4f88-4375-ba9b-878781b57eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = data[\"Class\"].astype(int)\n",
    "data.drop(\"Class\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c56564-6a0a-4726-8d55-ed7f3730dfa2",
   "metadata": {},
   "source": [
    "Fraud detection datasets are typically highly imbalanced, meaning the majority of transactions are legitimate. We check the distribution of our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfefa617-6cd7-40f3-81ae-4aa1c2aa2ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32d7aa-bf49-4767-a588-22ab47d78a14",
   "metadata": {},
   "source": [
    "We split our dataset into two parts:\n",
    "\n",
    "- Training set (80%): Used to train the machine learning model.\n",
    "- Testing set (20%): Used to evaluate the performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec82ed34-ae5d-4102-a67d-b3f6956a435c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size = 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00319219-04c0-4f9c-a59e-eaa3809ef84b",
   "metadata": {},
   "source": [
    "Let's also save it to Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b804dd-9d24-46d4-8f23-cf2b1340dbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"gs://{PROJECT_ID}-bucket/data/vertex/X_train.csv\", index=False)\n",
    "y_train.to_frame().to_csv(f\"gs://{PROJECT_ID}-bucket/data/vertex/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7627f-aacd-401f-b32b-d39f690c3172",
   "metadata": {},
   "source": [
    "## Train a Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9bdfa-a156-45db-b466-2a10e1539a78",
   "metadata": {},
   "source": [
    "We use a `RandomForestClassifier`, which is an ensemble learning method that creates multiple decision trees and aggregates their predictions. This helps improve accuracy and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f91fb92-47a9-4e93-8a68-35974c0fbca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   55.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=8, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b7cd00-ded8-4eac-a4a4-6ed12abc0ce0",
   "metadata": {},
   "source": [
    "We calculate the accuracy of the model, which measures the proportion of correctly classified instances.\n",
    "\n",
    "For a highly imbalanced data set, the accuracy is often meaningless, because a simple classifier that always says ***not fraud*** will have an accuracy close to 1 already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35eb9ac3-0897-429d-b2cc-4e4d440cb648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996313331694814"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e458e-03a3-4d2a-9b97-2b4760ac7118",
   "metadata": {},
   "source": [
    "We compute the ROC AUC (Receiver Operating Characteristic - Area Under the Curve) score. This metric evaluates the model's ability to distinguish between classes. A score closer to 1 indicates better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb3e080-b7ff-46c6-aff0-7da10ed4b76a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484577010437408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb1b11-aba7-46a4-89a7-0c020d34fef9",
   "metadata": {},
   "source": [
    "We save the trained model to a local file so we can deploy it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1c581a-7f80-4582-9c56-bf3a3563001a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5826c-7da4-42f8-bcc6-dd5188acbf59",
   "metadata": {},
   "source": [
    "We upload the trained model to Vertex AI, where it can be used for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283a9fe3-1f24-4fef-a870-d49f4fd99d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  1.3 MiB/  1.3 MiB]                                                \n",
      "Operation completed over 1 objects/1.3 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp model.joblib gs://{PROJECT_ID}-bucket/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150706a1-c207-4051-94e2-b8acac8387e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Serve locally trained model on Vertex AI\n",
    "\n",
    "The Vertex AI Model Registry is a centralized repository in Google Cloud's Vertex AI platform where machine learning (ML) models are stored, managed, and versioned. It allows data scientists and ML engineers to track different model versions, store metadata, and deploy models seamlessly to Vertex AI endpoints for inference.\n",
    "\n",
    "Key features of the Model Registry include:\n",
    "\n",
    "* Model Versioning: Track multiple versions of a model.\n",
    "* Metadata Management: Store details such as model parameters, training data, and performance metrics.\n",
    "* Deployment & Serving: Deploy registered models to Vertex AI Endpoints, Batch Predictions, or export them for external use.\n",
    "* Model Governance: Manage access control, approval workflows, and lineage tracking.\n",
    "* Integration with Pipelines: Automate model registration via Vertex AI Pipelines.\n",
    "\n",
    "We can register the model we just trained in this notebook as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf07af9-6490-4a6e-9ff8-6304eeb5feff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/888342260584/locations/us-central1/models/2743691629138280448/operations/9127100894670749696\n",
      "Model created. Resource name: projects/888342260584/locations/us-central1/models/2743691629138280448@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/888342260584/locations/us-central1/models/2743691629138280448@1')\n"
     ]
    }
   ],
   "source": [
    "vertex_model_upload = aiplatform.Model.upload(\n",
    "    display_name=\"bootkon-upload-model\",\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-5:latest\",\n",
    "    artifact_uri=f\"gs://{PROJECT_ID}-bucket/model/\",\n",
    "    is_default_version=True,\n",
    "    version_aliases=[\"v1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc86b2-ddfb-4b7b-a129-e3127a6c7362",
   "metadata": {},
   "source": [
    "Once the model has been uploaded, navigate to the [`Model Registry` in Vertex AI](https://console.cloud.google.com/vertex-ai/models). Click on `bootkon-model`. Can you find your newly created model artifact? Open the `VERSION DETAILS` tab and try to find your model artifact on Cloud Storage.\n",
    "\n",
    "Let's deploy the model to an endpoint for online prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd6e9ab8-e08b-453f-85be-59b95c933b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/888342260584/locations/us-central1/endpoints/4438641579913117696/operations/8052147958612754432\n",
      "Endpoint created. Resource name: projects/888342260584/locations/us-central1/endpoints/4438641579913117696\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/888342260584/locations/us-central1/endpoints/4438641579913117696')\n"
     ]
    }
   ],
   "source": [
    "endpoint_upload = aiplatform.Endpoint.create(display_name=\"bootkon-endpoint-upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d151a-c23e-4da0-923c-7bb3cc807972",
   "metadata": {},
   "source": [
    "The next code chunk will take around 10min. We don't want to wait for that, so we set `sync=False` and look at the result later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40f9482d-125c-43fd-a5fb-2042cd6f4b98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/888342260584/locations/us-central1/endpoints/4438641579913117696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f722ebaf040> \n",
       "resource name: projects/888342260584/locations/us-central1/endpoints/4438641579913117696"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy Endpoint model backing LRO: projects/888342260584/locations/us-central1/endpoints/4438641579913117696/operations/3505482659805528064\n"
     ]
    }
   ],
   "source": [
    "vertex_model_upload.deploy(\n",
    "    deployed_model_display_name=\"bootkon-model-upload\",\n",
    "    endpoint=endpoint_upload,\n",
    "    machine_type=\"n2-standard-2\",\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0581c19-50bd-4fc2-be82-9bc564c4baca",
   "metadata": {},
   "source": [
    "The next chunk lists the currently deployed models. While the model is deploying, it wont's show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9d2a32-7847-47a1-aa44-ed9f41f538b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_upload.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2828f-8fc4-4f95-bd02-04995afd9aa8",
   "metadata": {},
   "source": [
    "## Train and serve model using custom containers\n",
    "\n",
    "In this section, we will train a `RandomForestClassifier` using **custom containers** on Vertex AI and deploy it for real-time predictions. Instead of using pre-built containers, we will package our training and prediction logic into Docker containers, allowing for **full control over dependencies, runtime environments, and scalability**. \n",
    "\n",
    "The process consists of two main steps:\n",
    "1. **Model Training:** We will preprocess the dataset, train a model and save it as a serialized `joblib` file. The trained model will be uploaded to Cloud Storage for deployment.\n",
    "2. **Model Serving:** Using a separate container, the stored model will be loaded from Cloud Storage, and an API will be exposed via Flask (or **FastAPI** in production) to handle inference requests.\n",
    "\n",
    "By leveraging Vertex AI’s custom training and prediction services, we can achieve a **scalable, managed ML workflow** while keeping complete flexibility over the training and deployment pipeline.\n",
    "\n",
    "We will create the following files:\n",
    "\n",
    "- `train/Dockerfile`: Dockerfile for the training container\n",
    "- `train/train.py`: Training script\n",
    "- `predict/Dockerfile`: Dockerfile for the prediction container\n",
    "- `predict/predict.py`: Prediction script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa8927f0-3c70-4d10-a353-4f223ffb5f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738672582.497967 1300442 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "mkdir -p train predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bb918e4-b734-4975-9f6a-bde944794b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/Dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY train.py /app/train.py\n",
    "\n",
    "RUN pip install --no-cache-dir --quiet pandas scikit-learn==1.5.2 google-cloud-storage fsspec gcsfs\n",
    "\n",
    "ENTRYPOINT [\"python\", \"/app/train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fa30621-9df7-43ab-abcd-64f6c5b6f1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict/Dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY predict.py /app/predict.py\n",
    "\n",
    "RUN pip install --no-cache-dir --quiet pandas scikit-learn==1.5.2 google-cloud-storage google-cloud-aiplatform fsspec gcsfs flask\n",
    "EXPOSE 8080\n",
    "ENTRYPOINT [\"python\", \"/app/predict.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aabe48-5c59-48f7-afed-0b7c4c40eea7",
   "metadata": {},
   "source": [
    "The `train.py` script trains a `RandomForestClassifier` using scikit-learn, saves it as a `joblib` file, and uploads it to Cloud Storage. It reads the training data (`X_train` and `y_train`) from CSV files provided as command-line arguments and retrieves the target storage directory from the `AIP_MODEL_DIR` environment variable. The trained model is stored in GCS for later deployment on Vertex AI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af82d431-2684-4364-a0fe-01610e9ea191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/train.py\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from google.cloud import storage\n",
    "\n",
    "X_train = pd.read_csv(sys.argv[1])\n",
    "y_train = pd.read_csv(sys.argv[2])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=8, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, \"model.joblib\")\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(os.environ[\"AIP_MODEL_DIR\"].split(\"/\")[2])\n",
    "blob = bucket.blob(\"/\".join(os.environ[\"AIP_MODEL_DIR\"].split(\"/\")[3:]) + \"model.joblib\")\n",
    "blob.upload_from_filename(\"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5d45d-be53-405c-994b-b9367f6793a9",
   "metadata": {},
   "source": [
    "The `predict.py` script is a flask-based prediction server designed for deployment on Vertex AI using custom containers. It retrieves the model artifacts from Cloud Storage using `prediction_utils.download_model_artifacts()`, loads the model with `joblib`, and exposes two API endpoints:\n",
    "\n",
    "- **`/predict`** for inference  \n",
    "- **`/health`** for monitoring the service status  \n",
    "\n",
    "The script reads environment variables such as `AIP_STORAGE_URI` for downloading the model and `AIP_PREDICT_ROUTE` for defining the prediction route dynamically. \n",
    "\n",
    "⚠ **In production,** it is recommended to use **FastAPI** instead of Flask due to its superior performance, asynchronous capabilities, and built-in request validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63cccaed-feed-4e7d-a653-5b2ec5501aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict/predict.py\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import flask\n",
    "import numpy as np\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "prediction_utils.download_model_artifacts(os.environ[\"AIP_STORAGE_URI\"])\n",
    "model = joblib.load(\"model.joblib\")\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "@app.route(os.environ.get(\"AIP_PREDICT_ROUTE\", \"/predict\"), methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = flask.request.get_json()\n",
    "    inputs = np.array(data[\"instances\"])\n",
    "    predictions = model.predict(inputs).tolist()\n",
    "    return flask.jsonify({\"predictions\": predictions})\n",
    "\n",
    "@app.route(os.environ.get(\"AIP_HEALTH_ROUTE\", \"/health\"), methods=[\"GET\"])\n",
    "def health_check():\n",
    "    print(\"Received health check\")\n",
    "    return flask.jsonify({\"status\": \"healthy\"}), 200\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=int(os.environ.get(\"AIP_HTTP_PORT\", 8080)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55c6a141-8473-4483-809f-56ea486a02d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create bootkon --repository-format=docker --location={REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eea2ef0e-ee30-4d8d-a180-7c1378ad8a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/bootkon/bootkon-train:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56ff30c9-63ac-4a18-a49e-687d9ec7bae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PREDICT_IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/bootkon/bootkon-predict:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3cefa6-5d11-46be-9e6a-9d4209afb46b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary archive of 2 file(s) totalling 809 bytes before compression.\n",
      "Uploading tarball of [.] to [gs://astute-ace-336608_cloudbuild/source/1738672584.702657-9b8aa96a022548cfbd47c778f7bbf51b.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/astute-ace-336608/locations/us-central1/builds/ff552883-06d5-442f-8d3c-f8dc27292bec].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/ff552883-06d5-442f-8d3c-f8dc27292bec?project=888342260584 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"ff552883-06d5-442f-8d3c-f8dc27292bec\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://astute-ace-336608_cloudbuild/source/1738672584.702657-9b8aa96a022548cfbd47c778f7bbf51b.tgz#1738672585015672\n",
      "Copying gs://astute-ace-336608_cloudbuild/source/1738672584.702657-9b8aa96a022548cfbd47c778f7bbf51b.tgz#1738672585015672...\n",
      "/ [1 files][  677.0 B/  677.0 B]                                                \n",
      "Operation completed over 1 objects/677.0 B.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  3.584kB\n",
      "Step 1/5 : FROM python:3.10-slim\n",
      "3.10-slim: Pulling from library/python\n",
      "c29f5b76f736: Pulling fs layer\n",
      "74e68b11a1c1: Pulling fs layer\n",
      "a477a912afa7: Pulling fs layer\n",
      "8c67a072a8ad: Pulling fs layer\n",
      "8c67a072a8ad: Waiting\n",
      "74e68b11a1c1: Download complete\n",
      "a477a912afa7: Verifying Checksum\n",
      "a477a912afa7: Download complete\n",
      "8c67a072a8ad: Verifying Checksum\n",
      "8c67a072a8ad: Download complete\n",
      "c29f5b76f736: Verifying Checksum\n",
      "c29f5b76f736: Download complete\n",
      "c29f5b76f736: Pull complete\n",
      "74e68b11a1c1: Pull complete\n",
      "a477a912afa7: Pull complete\n",
      "8c67a072a8ad: Pull complete\n",
      "Digest: sha256:5669687dc31ef31ce93a945b6a14ddee3b35772f18106ba89598e5a0a6265b3e\n",
      "Status: Downloaded newer image for python:3.10-slim\n",
      " ---> b791f5ccaef8\n",
      "Step 2/5 : WORKDIR /app\n",
      " ---> Running in 50d8419dcac4\n",
      "Removing intermediate container 50d8419dcac4\n",
      " ---> 819767cb4443\n",
      "Step 3/5 : COPY train.py /app/train.py\n",
      " ---> 6771bafc766e\n",
      "Step 4/5 : RUN pip install --no-cache-dir --quiet pandas scikit-learn==1.5.2 google-cloud-storage fsspec gcsfs\n",
      " ---> Running in 2bbf4f82d2f0\n"
     ]
    }
   ],
   "source": [
    "!cd train && gcloud builds submit --region={REGION} --tag={TRAIN_IMAGE_URI} --timeout=1h --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e0f7c-43ff-454f-83b8-7c353b374a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd predict && gcloud builds submit --region={REGION} --tag={PREDICT_IMAGE_URI} --timeout=1h --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61caf649-0c92-4bd0-b2d9-8037bc132b9c",
   "metadata": {},
   "source": [
    "You can make predictions by using the `.predict` function of the endpoint instance. The next chunk predicts the first 2000 examples in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6594f-c9ed-40cc-a919-c7a92114ee4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name = \"bootkon-custom\",\n",
    "    container_uri = TRAIN_IMAGE_URI,\n",
    "    model_serving_container_image_uri = PREDICT_IMAGE_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b9420-e8ec-4b13-9f9e-9ae24a71a81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertex_model_custom = job.run(\n",
    "    args=[\n",
    "        f\"gs://{PROJECT_ID}-bucket/data/vertex/X_train.csv\",\n",
    "        f\"gs://{PROJECT_ID}-bucket/data/vertex/y_train.csv\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7315374-cd73-4bd8-8e2c-20815afa917a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_custom = aiplatform.Endpoint.create(display_name=\"bootkon-endpoint-custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02219939-8414-4bde-94ad-d3b97b003077",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_model_custom.deploy(\n",
    "    deployed_model_display_name=\"bootkon-model-custom\",\n",
    "    endpoint=endpoint_custom,\n",
    "    machine_type=\"n2-standard-2\",\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770835f3-1772-472f-8cf3-9a777290e3dc",
   "metadata": {},
   "source": [
    "## Train and deploy models using Vertex Pipelines\n",
    "\n",
    "**Vertex AI Pipelines** is a managed orchestration service in Vertex AI that enables the automation of machine learning (ML) workflows. It is built on **Kubeflow Pipelines (KFP)** and integrates seamlessly with **Vertex AI**, allowing for end-to-end ML lifecycle management, from data preparation to model training, evaluation, deployment, and monitoring.\n",
    "\n",
    "Key Features of Vertex AI Pipelines:\n",
    "\n",
    "- **Fully Managed Orchestration**: Vertex AI Pipelines automates ML workflows without the need to manage Kubernetes clusters manually. Google Cloud handles scaling, logging, and monitoring.\n",
    "\n",
    "- **Composable and Reusable Pipelines**: Pipelines are defined using Python-based Kubeflow Pipelines (KFP) SDK, allowing components to be modular, reusable, and easily shareable across different ML projects.\n",
    "\n",
    "- **Integration with Vertex AI Services**: Pipelines integrate seamlessly with Vertex AI services, such as Custom Training, Hyperparameter Tuning, Feature Store, and Model Deployment, enabling a streamlined ML workflow.\n",
    "\n",
    "- **Scalability and Parallel Execution**: Supports distributed execution, allowing multiple pipeline steps (e.g., data preprocessing, model training, and evaluation) to run in parallel, optimizing resource utilization.\n",
    "\n",
    "- **Artifact and Metadata Tracking**: All pipeline runs, datasets, and models are automatically tracked in Vertex ML Metadata, enabling easy debugging, reproducibility, and model lineage tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e9c47-a872-4523-988a-4a36185daae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f47601-028d-47d9-9c31-7ba0ab0e5ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db3cd1-8206-41cd-856a-3754b4d4c1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b95b55-5865-4049-bb5a-f21ea1b6d3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = endpoint_custom.predict(instances=X_test.head(2000).values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5feec-6866-4f96-b98e-d9d3b498f80d",
   "metadata": {},
   "source": [
    "Most of them are ***not fraud*** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3fc97-fc43-4eba-a819-337d23f3d942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response.predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145ffaa-8e0f-459c-93e3-dd637a308868",
   "metadata": {},
   "source": [
    "But there are also a few fraud cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef453a4-2254-4f0d-8fde-0568483ff063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(response.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77729c4e-516d-4cc4-9226-b90660df3e3c",
   "metadata": {},
   "source": [
    "## Challenge lab (optional)\n",
    "\n",
    "Can you make a prediction using the REST API? Go the the [Vertex Console](https://console.cloud.google.com/vertex-ai/online-prediction) and click on `SAMPLE REQUEST`. You can then open a Terminal (File -> New -> Terminal) and try it out."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
